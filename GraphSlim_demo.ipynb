{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code Demo of Using GraphSlim"
      ],
      "metadata": {
        "id": "1ymR6kPJJG54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Environment"
      ],
      "metadata": {
        "id": "4Wv_biUjHZHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If9ucY1O3Gx7",
        "outputId": "816cec04-a12c-49da-ba0f-b7dd95ab2dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphslim==1.1.1\n",
            "  Downloading graphslim-1.1.1.tar.gz (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (8.1.7)\n",
            "Collecting deeprobust (from graphslim==1.1.1)\n",
            "  Downloading deeprobust-0.2.11-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (5.1.0)\n",
            "Collecting networkit (from graphslim==1.1.1)\n",
            "  Downloading networkit-11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (1.26.4)\n",
            "Collecting ogb (from graphslim==1.1.1)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting PyGSP (from graphslim==1.1.1)\n",
            "  Downloading PyGSP-0.5.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (1.13.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (2.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (2.3.1+cu121)\n",
            "Collecting torch_geometric (from graphslim==1.1.1)\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from graphslim==1.1.1) (4.66.4)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.10/dist-packages (from deeprobust->graphslim==1.1.1) (3.7.1)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deeprobust->graphslim==1.1.1) (0.18.1+cu121)\n",
            "Collecting texttable>=1.6.2 (from deeprobust->graphslim==1.1.1)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.10/dist-packages (from deeprobust->graphslim==1.1.1) (0.60.0)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from deeprobust->graphslim==1.1.1) (9.4.0)\n",
            "Requirement already satisfied: scikit-image>=0.0 in /usr/local/lib/python3.10/dist-packages (from deeprobust->graphslim==1.1.1) (0.23.2)\n",
            "Collecting tensorboardX>=2.0 (from deeprobust->graphslim==1.1.1)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: gensim>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from deeprobust->graphslim==1.1.1) (4.3.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn->graphslim==1.1.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn->graphslim==1.1.1) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->graphslim==1.1.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->graphslim==1.1.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->graphslim==1.1.1) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->graphslim==1.1.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->graphslim==1.1.1) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->graphslim==1.1.1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->graphslim==1.1.1) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->graphslim==1.1.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->graphslim==1.1.1) (4.12.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->graphslim==1.1.1) (2.31.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb->graphslim==1.1.1) (2.1.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb->graphslim==1.1.1) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb->graphslim==1.1.1) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb->graphslim==1.1.1)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric->graphslim==1.1.1) (3.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->graphslim==1.1.1) (3.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->graphslim==1.1.1) (5.9.5)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.3.0->deeprobust->graphslim==1.1.1) (7.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->deeprobust->graphslim==1.1.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->deeprobust->graphslim==1.1.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->deeprobust->graphslim==1.1.1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->deeprobust->graphslim==1.1.1) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->deeprobust->graphslim==1.1.1) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.1.1->deeprobust->graphslim==1.1.1) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.48.0->deeprobust->graphslim==1.1.1) (0.43.0)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb->graphslim==1.1.1) (71.0.4)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->graphslim==1.1.1)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb->graphslim==1.1.1) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb->graphslim==1.1.1) (2024.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.0->deeprobust->graphslim==1.1.1) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.0->deeprobust->graphslim==1.1.1) (2024.7.24)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.0->deeprobust->graphslim==1.1.1) (0.4)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.0->deeprobust->graphslim==1.1.1) (3.20.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->graphslim==1.1.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->graphslim==1.1.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->graphslim==1.1.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->graphslim==1.1.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->graphslim==1.1.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric->graphslim==1.1.1) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->graphslim==1.1.1) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->graphslim==1.1.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->graphslim==1.1.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->graphslim==1.1.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->graphslim==1.1.1) (2024.7.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->graphslim==1.1.1) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->graphslim==1.1.1) (1.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim>=4.3.0->deeprobust->graphslim==1.1.1) (1.14.1)\n",
            "Downloading deeprobust-0.2.11-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading networkit-11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: graphslim\n",
            "  Building wheel for graphslim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphslim: filename=graphslim-1.1.1-py3-none-any.whl size=179538 sha256=10651acd5bad8537efd9d0364fbce47d12dde9b3f7816ba58ce9f834081bb28c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/06/67/4fe5e1aca6b482bacbbe69701d84bd0b71dcf3321d908f6afe\n",
            "Successfully built graphslim\n",
            "Installing collected packages: texttable, tensorboardX, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, PyGSP, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, networkit, torch_geometric, nvidia-cusolver-cu12, ogb, deeprobust, graphslim\n",
            "Successfully installed PyGSP-0.5.1 deeprobust-0.2.11 graphslim-1.1.1 littleutils-0.2.4 networkit-11.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ogb-1.3.6 outdated-0.2.2 tensorboardX-2.6.2.2 texttable-1.7.0 torch_geometric-2.5.3\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Installing collected packages: torch_scatter, torch_sparse\n",
            "Successfully installed torch_scatter-2.1.2+pt23cu121 torch_sparse-0.6.18+pt23cu121\n"
          ]
        }
      ],
      "source": [
        "! pip install graphslim==1.1.1\n",
        "! pip install torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "from graphslim.config import cli,method_config\n",
        "from graphslim.dataset import get_dataset\n",
        "from graphslim.evaluation import Evaluator\n",
        "from graphslim.sparsification import KCenter"
      ],
      "metadata": {
        "id": "I8d5wBoxEPrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Config"
      ],
      "metadata": {
        "id": "1QwvYj5WGo-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.argv = ['']\n",
        "args = cli(standalone_mode=False)\n",
        "args.method='kcenter'\n",
        "args=method_config(args)\n",
        "args"
      ],
      "metadata": {
        "id": "xSzOKanhEGA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7dbf175-4697-4452-a661-1f21e4eba53c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No config file found or error in json format.\n",
            "No config file found or error in json format.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'aggpreprocess': False,\n",
              " 'alpha': 0.1,\n",
              " 'attack': None,\n",
              " 'batch_adj': 1,\n",
              " 'checkpoints': [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
              "                 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
              "                 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
              "                 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
              "                 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
              "                 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96,\n",
              "                 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
              "                 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
              "                 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "                 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "                 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
              "                 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "                 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
              "                 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
              "                 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
              "                 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
              "                 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
              "                 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
              "                 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
              "                 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
              "                 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
              "                 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
              "                 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
              "                 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
              "                 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
              "                 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
              "                 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
              "                 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
              "                 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
              "                 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
              "                 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
              "                 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
              "                 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457,\n",
              "                 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469,\n",
              "                 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
              "                 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
              "                 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
              "                 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529,\n",
              "                 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
              "                 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
              "                 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
              "                 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
              "                 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
              "                 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
              "                 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613,\n",
              "                 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625,\n",
              "                 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n",
              "                 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
              "                 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661,\n",
              "                 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673,\n",
              "                 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
              "                 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697,\n",
              "                 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709,\n",
              "                 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721,\n",
              "                 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733,\n",
              "                 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745,\n",
              "                 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757,\n",
              "                 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769,\n",
              "                 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781,\n",
              "                 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793,\n",
              "                 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
              "                 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817,\n",
              "                 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829,\n",
              "                 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841,\n",
              "                 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853,\n",
              "                 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865,\n",
              "                 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877,\n",
              "                 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889,\n",
              "                 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901,\n",
              "                 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913,\n",
              "                 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925,\n",
              "                 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937,\n",
              "                 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949,\n",
              "                 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
              "                 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973,\n",
              "                 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985,\n",
              "                 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997,\n",
              "                 998, 999, 1000],\n",
              " 'coarsen_strategy': 'greedy',\n",
              " 'condense_model': 'SGC',\n",
              " 'dataset': 'cora',\n",
              " 'device': 'cuda:0',\n",
              " 'dis_metric': 'ours',\n",
              " 'dropout': 0.0,\n",
              " 'epochs': 1000,\n",
              " 'eval_epochs': 300,\n",
              " 'eval_interval': 1,\n",
              " 'eval_model': 'GCN',\n",
              " 'eval_whole': False,\n",
              " 'final_eval_model': 'GCN',\n",
              " 'gpu_id': 0,\n",
              " 'hidden': 256,\n",
              " 'init': None,\n",
              " 'inner_loop': 1,\n",
              " 'logger': <Logger graphslim.config (WARNING)>,\n",
              " 'lr': 0.01,\n",
              " 'lr_adj': 0.0001,\n",
              " 'lr_feat': 0.0001,\n",
              " 'method': 'kcenter',\n",
              " 'mx_size': 100,\n",
              " 'nlayers': 2,\n",
              " 'no_buff': False,\n",
              " 'ntrans': 1,\n",
              " 'optim': 'Adam',\n",
              " 'outer_loop': 10,\n",
              " 'pre_norm': True,\n",
              " 'ptb_r': 0.25,\n",
              " 'reduction_rate': 0.5,\n",
              " 'run_eval': 10,\n",
              " 'run_inter_eval': 3,\n",
              " 'run_reduction': 3,\n",
              " 'save_path': '../checkpoints',\n",
              " 'seed': 1,\n",
              " 'setting': 'trans',\n",
              " 'soft_label': 0,\n",
              " 'split': 'fixed',\n",
              " 'threshold': 0,\n",
              " 'ts': 4,\n",
              " 'verbose': False,\n",
              " 'weight_decay': 0.0,\n",
              " 'with_bn': False,\n",
              " 'with_structure': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Original Graph"
      ],
      "metadata": {
        "id": "PtuUSBUzG2tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = get_dataset(args.dataset, args)"
      ],
      "metadata": {
        "id": "5r81d1zm8Urc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277aa232-8a33-45ee-cfee-1de011d86c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Reduce Graph using **KCenter** Agent"
      ],
      "metadata": {
        "id": "LnBQ9g5wHBKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = KCenter(setting=args.setting, data=graph, args=args)\n",
        "reduced_graph = agent.reduce(graph)"
      ],
      "metadata": {
        "id": "nGd1Bmh2Gmkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Reduced Graph (Evaluate 10 Times with different seeds)"
      ],
      "metadata": {
        "id": "KTXw0MzoHE1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = Evaluator(args)\n",
        "res = evaluator.evaluate(reduced_graph, 'GCN')\n",
        "print('\\nTest Mean Result:', res[0], '+/-', res[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiEhuH0nGlM7",
        "outputId": "af3cd221-b4bd-48ba-92de-f2fcf30d5318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity: 0.0024489795918367346\n",
            "Evaluating reduced data using GCN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.20it/s, test_acc=0.704]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Mean Result: 0.7148 +/- 0.009765244492586948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Reduce Graph using **GCond** Agent"
      ],
      "metadata": {
        "id": "hLtPY0gSNZqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.argv = ['']\n",
        "args = cli(standalone_mode=False)\n",
        "args.method = 'gcond'\n",
        "args.dataset = 'cora'\n",
        "args = method_config(args)\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKZrpEWPGm_Z",
        "outputId": "976106a8-a0f1-44f3-b224-81d274bab649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No config file found or error in json format.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'aggpreprocess': False,\n",
              " 'alpha': 0.1,\n",
              " 'attack': None,\n",
              " 'batch_adj': 1,\n",
              " 'checkpoints': [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,\n",
              "                 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
              "                 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
              "                 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n",
              "                 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
              "                 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96,\n",
              "                 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
              "                 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
              "                 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
              "                 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
              "                 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
              "                 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
              "                 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "                 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
              "                 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
              "                 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
              "                 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
              "                 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
              "                 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
              "                 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
              "                 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
              "                 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289,\n",
              "                 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
              "                 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
              "                 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
              "                 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
              "                 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
              "                 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361,\n",
              "                 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373,\n",
              "                 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385,\n",
              "                 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
              "                 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
              "                 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
              "                 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
              "                 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
              "                 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457,\n",
              "                 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469,\n",
              "                 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
              "                 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
              "                 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505,\n",
              "                 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
              "                 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529,\n",
              "                 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
              "                 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
              "                 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
              "                 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
              "                 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
              "                 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
              "                 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613,\n",
              "                 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625,\n",
              "                 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n",
              "                 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
              "                 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661,\n",
              "                 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673,\n",
              "                 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685,\n",
              "                 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697,\n",
              "                 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709,\n",
              "                 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721,\n",
              "                 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733,\n",
              "                 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745,\n",
              "                 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757,\n",
              "                 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769,\n",
              "                 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781,\n",
              "                 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793,\n",
              "                 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
              "                 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817,\n",
              "                 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829,\n",
              "                 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841,\n",
              "                 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853,\n",
              "                 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865,\n",
              "                 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877,\n",
              "                 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889,\n",
              "                 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901,\n",
              "                 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913,\n",
              "                 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925,\n",
              "                 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937,\n",
              "                 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949,\n",
              "                 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
              "                 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973,\n",
              "                 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985,\n",
              "                 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997,\n",
              "                 998, 999, 1000],\n",
              " 'coarsen_strategy': 'greedy',\n",
              " 'condense_model': 'SGC',\n",
              " 'dataset': 'cora',\n",
              " 'device': 'cuda:0',\n",
              " 'dis_metric': 'ours',\n",
              " 'dropout': 0.0,\n",
              " 'epochs': 1000,\n",
              " 'eval_epochs': 300,\n",
              " 'eval_interval': 1,\n",
              " 'eval_model': 'GCN',\n",
              " 'eval_whole': False,\n",
              " 'final_eval_model': 'GCN',\n",
              " 'gpu_id': 0,\n",
              " 'hidden': 256,\n",
              " 'init': None,\n",
              " 'inner_loop': 15,\n",
              " 'logger': <Logger graphslim.config (WARNING)>,\n",
              " 'lr': 0.01,\n",
              " 'lr_adj': 0.0001,\n",
              " 'lr_feat': 0.0001,\n",
              " 'method': 'gcond',\n",
              " 'mx_size': 100,\n",
              " 'nlayers': 2,\n",
              " 'no_buff': False,\n",
              " 'ntrans': 1,\n",
              " 'optim': 'Adam',\n",
              " 'outer_loop': 20,\n",
              " 'pre_norm': True,\n",
              " 'ptb_r': 0.25,\n",
              " 'reduction_rate': 0.5,\n",
              " 'run_eval': 10,\n",
              " 'run_inter_eval': 3,\n",
              " 'run_reduction': 3,\n",
              " 'save_path': '../checkpoints',\n",
              " 'seed': 1,\n",
              " 'setting': 'trans',\n",
              " 'soft_label': 0,\n",
              " 'split': 'fixed',\n",
              " 'threshold': 0.05,\n",
              " 'ts': 4,\n",
              " 'verbose': False,\n",
              " 'weight_decay': 0.0,\n",
              " 'with_bn': False,\n",
              " 'with_structure': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphslim.condensation import GCond\n",
        "agent = GCond(setting=args.setting, data=graph, args=args)\n",
        "reduced_graph = agent.reduce(graph)\n",
        "evaluator = Evaluator(args)\n",
        "res = evaluator.evaluate(reduced_graph, 'GCN')\n",
        "print('\\nTest Mean Result:', res[0], '+/-', res[1])"
      ],
      "metadata": {
        "id": "H_t1FKy1GOKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8add5114-d7da-481a-a651-3c54b69035df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target reduced size:70\n",
            "actual reduced size:70\n",
            "adj_syn: (70, 70) feat_syn: torch.Size([70, 1433])\n",
            "selected nodes: 70\n",
            "induced edges: 6\n",
            "Function Time: 0.0052218449999941186 s\n",
            "Function Time: 5.2218449999941186 ms\n",
            "Original graph:0.77 Mb  Condensed graph:0.40 Mb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/999 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 999/999 [1:00:27<00:00,  3.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity: 0.9857142857142858\n",
            "Sparsity after truncating: 0.9048979591836734\n",
            "Evaluating reduced data using GCN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:08<00:00,  1.20it/s, test_acc=0.802]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Mean Result: 0.8159000000000001 +/- 0.007063285354564128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}